{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('orders_challengue_sep2023_PE_CO.csv', sep=\",\", engine='python')  \n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting NaN values in all columns\n",
    "nan_count = df.isna().sum()\n",
    "\n",
    "print(nan_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"TO_USER_DISTANCE\", \"TOTAL_EARNINGS\", \"DISTANCE_TO_STORE\", \"TIP\", \"SATURATION\", \"TAKEN\"]\n",
    "df.hist(column=columns, bins=120, layout=(2,3), figsize=(15,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define subplot layout\n",
    "fig, axes = plt.subplots(ncols=4, figsize=(15,5))\n",
    "\n",
    "#add DataFrames to subplots\n",
    "df[[\"TO_USER_DISTANCE\"]].boxplot(ax=axes[0])\n",
    "df[[\"TOTAL_EARNINGS\"]].boxplot(ax=axes[1])\n",
    "df[[\"DISTANCE_TO_STORE\"]].boxplot(ax=axes[2])\n",
    "df[[\"TIP\"]].boxplot(ax=axes[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=[object])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Countries:\", df[\"COUNTRY\"].unique())\n",
    "print(\"Cities:\", df[\"CITY\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"COUNTRY\", \"CITY\"]\n",
    "df[[\"COUNTRY\", \"CITY\"]].value_counts().plot(kind='bar', xlabel='CITY', ylabel='Count', rot=90, figsize=(15,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"COUNTRY\"].value_counts().plot(kind='bar', xlabel='COUNTRY', ylabel='Count', rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TAKEN\"].value_counts().plot(kind='bar', xlabel='TAKEN', ylabel='Count', rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Machine Learning model. Classification for TAKEN variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo datos y creando nuevas features...\n",
      "Dividiendo en conjunto de train y test (test_size=0.3)...\n",
      "Datos cargados!\n",
      "Ajustando preprocessor...\n",
      "Peprocessor ajustando!\n",
      "Transformando datos...\n",
      "Datos transformados!\n",
      "Transformando datos...\n",
      "Datos transformados!\n",
      "Ajustando el modelo de clasificación...\n",
      "Modelo ajustado!\n",
      "Acurracy Score: 0.6590150275212462\n",
      "Precision Score: 0.7633080216281484\n",
      "Recall Score: 0.7672350610678025\n",
      "f1 Score: 0.7652665033850017\n",
      "****************************************************************************************************\n",
      "Modelo guardado en: model.pkl\n",
      "Preprocessor guardado en: preprocessor.pkl\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "from ClassifierModel import DTCTrainer, DTCModel\n",
    "\n",
    "# Ejemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Instanciamos la clase de entrenamiento\n",
    "    trainer = DTCTrainer(test_size=0.3)\n",
    "    \n",
    "    # Get data\n",
    "    dataset_path = \"orders_challengue_sep2023_PE_CO.csv\"\n",
    "    X_train, X_test, y_train, y_test = trainer.get_data(dataset_path)\n",
    "      \n",
    "    # Transform data\n",
    "    X_train = trainer.fit_transform(X_train)\n",
    "    X_test = trainer.transform(X_test)\n",
    "\n",
    "    # Train model\n",
    "    trainer.train(X_train, y_train)\n",
    "    \n",
    "    # Evaluate model\n",
    "    accuracy_score, precision_score, recall_score, f1_score = trainer.evaluate(X_test, y_test)\n",
    "    print(\"Acurracy Score:\", accuracy_score)\n",
    "    print(\"Precision Score:\", precision_score)\n",
    "    print(\"Recall Score:\", recall_score)\n",
    "    print(\"f1 Score:\", f1_score)\n",
    "   \n",
    "    \n",
    "    # Save model, scaler, and encoder for categorical variables\n",
    "    trainer.save_model_scaler_enc(filepath_model=\"model.pkl\", filepath_preprocessor= \"preprocessor.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    filepath_model=\"model.pkl\"\n",
    "    filepath_preprocessor= \"preprocessor.pkl\"\n",
    "    \n",
    "    # Instanciamos la clase del modelo DecisionTreeClassifier\n",
    "    model = DTCModel(filepath_model, filepath_preprocessor)\n",
    "    \n",
    "    # Get data\n",
    "    data_path = \"test_set.csv\"\n",
    "    X = model.get_data(data_path)\n",
    "    \n",
    "    # Preprocess data\n",
    "    X = model.transform(X)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    print(\"Predictions:\\n\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo datos y creando nuevas features...\n",
      "Dividiendo en conjunto de train y test (test_size=0.3)...\n",
      "Datos cargados!\n",
      "Ajustando preprocessor...\n",
      "Peprocessor ajustando!\n",
      "Transformando datos...\n",
      "Datos transformados!\n",
      "Transformando datos...\n",
      "Datos transformados!\n",
      "Ajustando el modelo de clasificación...\n",
      "Modelo ajustado!\n",
      "Acurracy Score: 0.6590150275212462\n",
      "Precision Score: 0.7633080216281484\n",
      "Recall Score: 0.7672350610678025\n",
      "f1 Score: 0.7652665033850017\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Path 'DTCmodel' already exists and is not empty",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m filepath_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDTCmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     48\u001b[0m filepath_preprocessor\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 50\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msklearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m mlflow\u001b[38;5;241m.\u001b[39msklearn\u001b[38;5;241m.\u001b[39msave_model(trainer\u001b[38;5;241m.\u001b[39mpreprocessor, filepath_preprocessor)\n",
      "File \u001b[1;32mc:\\Users\\cami10\\miniconda3\\lib\\site-packages\\mlflow\\sklearn\\__init__.py:244\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(sk_model, path, conda_env, code_paths, mlflow_model, serialization_format, signature, input_example, pip_requirements, extra_pip_requirements, pyfunc_predict_fn, metadata)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m serialization_format \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SUPPORTED_SERIALIZATION_FORMATS:\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m    237\u001b[0m         message\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    238\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized serialization format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mserialization_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please specify one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    241\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mINVALID_PARAMETER_VALUE,\n\u001b[0;32m    242\u001b[0m     )\n\u001b[1;32m--> 244\u001b[0m \u001b[43m_validate_and_prepare_target_save_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m code_path_subdir \u001b[38;5;241m=\u001b[39m _validate_and_copy_code_paths(code_paths, path)\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mlflow_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\cami10\\miniconda3\\lib\\site-packages\\mlflow\\utils\\model_utils.py:267\u001b[0m, in \u001b[0;36m_validate_and_prepare_target_save_path\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_and_prepare_target_save_path\u001b[39m(path):\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(path) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(os\u001b[38;5;241m.\u001b[39mscandir(path)):\n\u001b[1;32m--> 267\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m    268\u001b[0m             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPath \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already exists and is not empty\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    269\u001b[0m             error_code\u001b[38;5;241m=\u001b[39mRESOURCE_ALREADY_EXISTS,\n\u001b[0;32m    270\u001b[0m         )\n\u001b[0;32m    272\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(path, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mMlflowException\u001b[0m: Path 'DTCmodel' already exists and is not empty"
     ]
    }
   ],
   "source": [
    "# Import mlflow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from ClassifierModel import DTCTrainer, DTCModel\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "\n",
    "# Start an MLflow run; the \"with\" keyword ensures we'll close the run even if this cell crashes\n",
    "with mlflow.start_run():\n",
    "    # Instanciamos la clase de entrenamiento\n",
    "    trainer = DTCTrainer(test_size=0.3)\n",
    "    \n",
    "    # Get data\n",
    "    dataset_path = \"orders_challengue_sep2023_PE_CO.csv\"\n",
    "    X_train, X_test, y_train, y_test = trainer.get_data(dataset_path)\n",
    "      \n",
    "    # Transform data\n",
    "    X_train = trainer.fit_transform(X_train)\n",
    "    X_test = trainer.transform(X_test)\n",
    "\n",
    "    # Train model\n",
    "    trainer.train(X_train, y_train)\n",
    "    \n",
    "    # Evaluate model\n",
    "    accuracy_score, precision_score, recall_score, f1_score = trainer.evaluate(X_test, y_test)\n",
    "\n",
    "    # Print model metrics\n",
    "    print(\"Acurracy Score:\", accuracy_score)\n",
    "    print(\"Precision Score:\", precision_score)\n",
    "    print(\"Recall Score:\", recall_score)\n",
    "    print(\"f1 Score:\", f1_score)\n",
    "    \n",
    "    # Log mlflow attributes for mlflow UI\n",
    "    mlflow.log_param(\"acurracy\", accuracy_score)\n",
    "    mlflow.log_param(\"precision\", precision_score)\n",
    "    mlflow.log_metric(\"recall\", recall_score)\n",
    "    mlflow.log_metric(\"f1_score\", f1_score)\n",
    "\n",
    "    # Signature\n",
    "    signature = infer_signature(X_train, y_train)\n",
    "    \n",
    "    mlflow.sklearn.log_model(trainer.model, \"DTCmodel\", signature=signature)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
